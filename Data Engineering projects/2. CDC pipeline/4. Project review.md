# Project review

For this project, I was able to devise a successful CDC pipeline that moved data from one database to another via AWS. This project didn't come without its challenges, however. delete. 


## Challenges and solutions

I overcame a series of challenges throughout this project that I outline below.

<ins>Issues using S3 as the target at the end of the pipeline</ins>
<br>
Initially, my CDC pipeline consisted of a MySQL database and S3 bucket as the DMS source and target respectively, before ending the pipeline with another S3 bucket. Unlike MySQL and PostgreSQL, S3 buckets store data in .csv files instead of tables so a file path must be specified to read and write data there. Writing the full load from the first S3 bucket to the final S3 bucket worked fine, but issues arose when the Glub job attempted to overwrite this data with the same changes made at the source database. My first attempts to do so resulted in the following error:

<i>java.io.FileNotFoundException: No such file or directory: [S3 file path]</i>

This problem can occur when reading and writing data into the same location. As a workaround, I cached the changed data before it was loaded into the final S3 bucket by performing the .cache() action on its dataframe followed by the .show() action. Caching the dataframe stores its data in memory so that when a subsequent action is performed on it (e.g. write), all Spark has to do is retrieve its data from this memory space instead of having to build the dataframe from scratch again. Writing the changed data from the dataframe to the target S3 file in overwrite mode (i.e. overwriting) actually deletes the original file from which it came and replaces it with a new file. When you don't cache, Spark attempts to rebuild the dataframe by reading data from the original data that has since been deleted thanks to overwrite mode which is how we get the above error. 

This workaround erased this error and the result should have left us with a single output file in the final S3 bucket containing all the UPDATE, DELETE and INSERT changes made to the data. Instead, I was left with 4 files: 1 file with the UPDATE and DELETE change made to the data, and 3 other files (one for each new row to be inserted into the data). So for some reason the INSERT changes weren't collated with the others changes in one file. 

Ultimately I decided to change my CDC pipeline by instead using a PostgreSQL database as my source and a MySQL database as the target at the end of the CDC pipeline, keeping an S3 as the DMS target in the middle of pipeline. 


<ins>Connection failure between PostgreSQL source endpoint and replication instance in DMS</ins>
<br>
In order for a DMS migration task to succeed, a connection must be established between the replication instance and its endpoints so that data can move from one database to another. Initially, the connection between the source endpoint and the replication instance failed due to the following error:

<i>Message: FATAL: no pg_hba.conf entry for host "xxx.xx.xx.xx", user "xxxxx", database "xxxxx", no encryption</i>

That's because for PostgreSQL versions 15 onwards, SSL (a protocol which ensures a private connection between servers by encrypting data) is automatically turned on. When SSL is turned on, you must manually configure SSL on PostgreSQL for its data to be accessed. Configuring SSL is an extra lengthy step that isn't necessary for this project. Instead, you must turn off SSL by setting its paramater <i>rds.force_ssl</i> to 0 in the database's associated parameter group.

After doing so, I came across another error:

<i>Message: FATAL: database "[database_identifier]" does not exist</i>

When creating a database in RDS, it is very important to distinguish between its <b>database identifier</b> and its <b>database name</b>. The identifier is a unique name you must give to let AWS distinguish between different databases you have made. Giving a database name, however, is optional as part of the <i>Additional configuration</i> section of database set-up. If a database name is not given for PostgreSQL, it automatically defaults to the name <i>postgres</i>.

When creating a DMS source endpoint for this database, it asks you to specify the database name. Initially I set this to the database identifier assuming they were the same when this wasn't the case. I didn't create a database name upon database set-up so DMS was in fact looking for its default database name <i>postgres</i> to establish a connection which is why we get the above error. Modifying the source endpoint by specifying the default database name fixed this error and finally a connection between the source endpoint and replication instance was established. 


<ins>UPDATE and DELETE changes not replicated in MySQL target database</ins>
<br>
When preparing PostgreSQL for CDC, it was important to assign its table with a primary key to identify which rows would be changed and how. But when I first made these changes to the source data, the resultant MySQL table only contained the new rows caused by INSERT commands. None of the previous data alongside any UPDATE and DELETE changes existed anymore.

To fix this, we first need to apply the same primary key constraint ('ChartDate_WeekEnding' column) to the target MySQL table. We can do this by creating a new table with a schema containing this primary key constraint before starting the DMS migration task. Next, remember that overwriting a file or table with data changes deletes that table and replaces it with a new one. Deleting or dropping the target table also gets rid of its previous schema which we don't want as it also gets rid of the table's primary key that we need.

The solution? Edit the Glue job script by adding the truncate write option (<i>.option("truncate","true")</i>) anytime we write data to the MySQL database. Once that's been edited, you can start the DMS migration task to kick off the CDC pipeline. 




