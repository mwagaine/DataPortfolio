{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5150a6a7-ea72-435e-ab38-fe7a5e0cb63e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setting-up the Lambda function\n",
    "\n",
    "<ol>\n",
    "  <li>Log-in to AWS and head to the IAM Management Console to create a new role with a Lambda use case, attaching the following policies:\n",
    "    <ul>\n",
    "      <li><i>S3FullAccess</i></li>\n",
    "      <li><i>CloudWatchFullAccess</i></li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>Go to the Lambda Console and create a new function, selecting the option <i>Author from scratch</i>.\n",
    "  <br>\n",
    "  In the <i>Change default execution role</i> section, select <i>Use an existing role</i> to add the IAM role you've created.\n",
    "  </li>\n",
    "  <li>Once the function has been created, add an S3 trigger. Select the bucket created earlier and used for DMS where data will be loaded into.\n",
    "  <li>In the <i>Code</i> tab, delete the default code present and replace it with the code in this notebook below, before clicking <i>Deploy</i>.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65d19c29-23d8-4f2d-be5f-492ce96ba4ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# Create function to extract the filename of the data and the name of its S3 bucket\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    bucketName = event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]\n",
    "    fileName = event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]\n",
    "\n",
    "    glue = boto3.client('glue')\n",
    "    \n",
    "    # The JobName specified here should be used when naming the Glue job to be \n",
    "    # created in the next step of this project\n",
    "    response = glue.start_job_run(\n",
    "        JobName = 'glueCDC-pyspark',\n",
    "        Arguments = {\n",
    "            '--s3_target_path_key': fileName,\n",
    "            '--s3_target_path_bucket': bucketName\n",
    "        } \n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps('Hello from Lambda!')\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1. Lambda function",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
